import streamlit as st
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Streamlitã®ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Chat Interface",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .stApp {
        max-width: 1980px !important;
        margin: 0 auto;
    }
    .main .block-container {
        max-width: 1980px !important;
        padding-left: 5rem;
        padding-right: 5rem;
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        min-height: 1080px;
    }
</style>
""", unsafe_allow_html=True)

# æ–‡æ›¸ãŒå‡¦ç†ã•ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç†
if 'processed_docs' not in st.session_state or not st.session_state.processed_docs:
    st.error("ğŸ˜… No documents found. Please upload documents in the Document Upload page first!")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé¸æŠ
with st.sidebar:
    st.header("ğŸ’¬ Chat Settings")
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé¸æŠ
    selected_doc = st.selectbox(
        "Select Document",
        options=list(st.session_state.processed_docs.keys()),
        key="document_selector"
    )
    
    # ä¼šè©±ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if selected_doc:
        if 'conversation_chains' not in st.session_state:
            st.session_state.conversation_chains = {}
        
        if selected_doc not in st.session_state.conversation_chains:
            st.session_state.conversation_chains[selected_doc] = ConversationalRetrievalChain.from_llm(
                llm=ChatOpenAI(
                    temperature=st.session_state.get('temperature', 0.7),
                    openai_api_key=os.getenv("OPENAI_API_KEY")
                ),
                retriever=st.session_state.processed_docs[selected_doc]['vectorstore'].as_retriever(
                    search_kwargs={"k": 3}
                ),
                verbose=True
            )
    
    # è¨­å®š
    st.subheader("âš™ï¸ Settings")
    temperature = st.slider(
        "AI Response Creativity",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.get('temperature', 0.7),
        step=0.1
    )
    st.session_state.temperature = temperature
    
    # ç¾åœ¨ã®ä¼šè©±ã‚’ã‚¯ãƒªã‚¢
    if st.button("ğŸ—‘ï¸ Clear Current Chat"):
        if selected_doc in st.session_state.processed_docs:
            st.session_state.processed_docs[selected_doc]['messages'] = []
            st.experimental_rerun()

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title(f"ğŸ’¬ Chat with: {selected_doc}")

# é¸æŠã•ã‚ŒãŸæ–‡æ›¸ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
with st.expander("ğŸ“„ Document Preview"):
    st.write(st.session_state.processed_docs[selected_doc]['summary'])

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
messages = st.session_state.processed_docs[selected_doc]['messages']
for message in messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("Ask me anything about the document..."):
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®æº–å‚™
    chat_history = [(msg["role"], msg["content"]) for msg in messages]
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤ºã¨ä¿å­˜
    st.session_state.processed_docs[selected_doc]['messages'].append({
        "role": "user", 
        "content": prompt
    })
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            # ä¼šè©±ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            result = st.session_state.conversation_chains[selected_doc]({
                "question": prompt,
                "chat_history": chat_history
            })
            
            answer = result["answer"]
            
            # å¿œç­”ã®è¡¨ç¤º
            st.markdown(answer)
            
            # å¿œç­”ã®ä¿å­˜
            st.session_state.processed_docs[selected_doc]['messages'].append({
                "role": "assistant",
                "content": answer
            })
